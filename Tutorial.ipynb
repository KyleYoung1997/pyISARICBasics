{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899fa589",
   "metadata": {},
   "source": [
    "# pyISARICBasics Tutorial\n",
    "\n",
    "Author: Kyle G Young\n",
    "\n",
    "This tutorial introduces the user to the ISARIC dataset and provides an overview of some basic data exploration tools that can be used for each domain. \n",
    "\n",
    "The package includes functions to read and write data from the raw .csv files. It includes a Domain Class to load and explore a specific domain. The package relies heavily on Pandas (https://pandas.pydata.org)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f040262",
   "metadata": {},
   "source": [
    "In this tutorial we will create a sqlite database and do some data exploration and analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c0814",
   "metadata": {},
   "source": [
    "## Sqlite Database Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d2073",
   "metadata": {},
   "source": [
    "We first set some global variables. DATA_DIRECTORY is a path to the directory where the raw ISARIC .csv's are contained. While DATABASE_FILE is what we want the sqlite database to be named. In addition the sqlite database will also be created inside the directory specified by DATA_DIRECTORY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf843d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"path_to_data\"\n",
    "DATABASE_FILE = \"data.sqlite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c00528c",
   "metadata": {},
   "source": [
    "We now import the Domain Class and some useful functions from the pyISARICBasics package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1853e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIP install\n",
    "from pyISARICBasics.domain import Domain\n",
    "from pyISARICBasics.functions import csv_to_sqlite, df_to_sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac6417",
   "metadata": {},
   "source": [
    "The first step in our data exploration / analysis is to convert all of our raw .csv's to a sqlite database. This is useful for browsing with the application DB Browser (https://sqlitebrowser.org).\n",
    "\n",
    "Unfortunately reading and writing full sqlite tables into memory as a dataframe is not particularly efficient in Python 3. However the following function also creates auxiliary .pickle files that contain a serialised version of pandas DataFrame objects - loading these files is much more efficient. Generating the inital database can take some time (approximately 20mins on a laptop), we suggest you let this run and then have a read through the pyIsaricBasics documentation: (https://kyleyoung1997.github.io/pyISARICBasics/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_sqlite(DATA_DIRECTORY, DATABASE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be4571",
   "metadata": {},
   "source": [
    "## Data Exploration using the SA domain\n",
    "\n",
    "Let's load the SA domain as an example: \n",
    "\n",
    "The domain class contains four arguements: Domain(domain, data_directory, num_rows). \n",
    "\n",
    "1. domain: (string): specifying the name of the domain we wish to load e.g. \"SA\"\n",
    "2. data_directory: (string): A path to the directory containing the raw ISARIC .csv's (if you've been following along you should have set this up above) \n",
    "3. num_rows: (int): An optional argument that can be used to specify how many rows of data we wish to load. If we wish to load all the data we can leave this blank or specify num_rows = None\n",
    "\n",
    "Some of the ISARIC domains contain a large number of rows, if you're just exploring the dataset or testing functions it might be useful to only load a subset of rows. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de54622",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA = Domain(\"SA\", DATA_DIRECTORY, num_rows = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ef914",
   "metadata": {},
   "source": [
    "Let's look at the columns in this domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1151b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd94078",
   "metadata": {},
   "source": [
    "All the columns in UPPERCASE are unaltered from the original SA csv file. We also have one extra column 'status', which converts the outcomes from ISARIC / STDM format into a simple \"Y\", \"N\" or \"U\". (Yes, no or unknown). we will use the convention of lower case for the names of any columns that we create or derive ourselves. \n",
    "\n",
    "Some important columns from the original ISARIC data are:\n",
    "    \n",
    "    xxTERM - Contains the verbatim non-standardised wording of an event\n",
    "    xxOCCUR - Helps to determine whether an event occured or not\n",
    "    xxPREPSP - a value of 'y' in this column indicates that the event was prespecified on the CRF, while 'n' or missing indicates a spontaneous (or free-text entry)\n",
    "    xxSTDY - Gives the day of an event (relative to admission day) \n",
    "    \n",
    "The 'status' column indicates whether an event occurred based on the combination of values in xxPRESP and xxOCCUR as follows: \n",
    "\n",
    "| xxPRESP | xxOCCUR | status |\n",
    "|---------|---------|--------|\n",
    "| NA      | NA      | Y      |\n",
    "| NA      | Y       | U      |\n",
    "| N       | Y       | N      |\n",
    "| U       | Y       | U      |\n",
    "| Y       | NA      | Y      |\n",
    "| Y       | Y       | Y      |\n",
    "\n",
    "\n",
    "Source code and documentation for this function can be viewed at (https://kyleyoung1997.github.io/pyISARICBasics/domain.html#pyISARICBasics.domain.Domain.process_occur) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b062f3",
   "metadata": {},
   "source": [
    "Now we know what the columns in our table are, it could be useful to look at the missingness in different columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.table_missingness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c5890",
   "metadata": {},
   "source": [
    "This method prints out the number of rows in each column that have missing values, as well as the total number of rows in the domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcd9109",
   "metadata": {},
   "source": [
    "As you can see there is a large number of columns with high missingness. We can choose to exclude some of these columns from our dataframe, to free up memory and make computations more time efficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d10733",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.exclude_columns(['SASCAT', \"SASTAT\", \"SAREASND\", \"SALOC\", \"SATPT\", \"SATPTREF\", \"SASTRF\", \"SAEVINTX\", \"SARPOC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a5007",
   "metadata": {},
   "source": [
    "We can use the following method to display all events in a given column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1366d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.column_events(\"SAMODIFY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083e296",
   "metadata": {},
   "source": [
    "We can now look at the table missingness while filtering on a specific variable. For example if we are interested in 'HYPERTENSION' we can examine the missingness for only those rows where there is an entry for \"HYPERTENSION\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.table_missingness(\"SAMODIFY\", \"HYPERTENSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f879b",
   "metadata": {},
   "source": [
    "This output displays the missingness for the 632,964 rows where SAMODIFY contains HYPERTENSION, of the 677,926 unique patients in the SA domain, there are 631,160 that have an entry for HYPERTENSION."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77917888",
   "metadata": {},
   "source": [
    "Now let's take a closer look at the filtered DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79bc73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.select_variable_from_column(\"SAMODIFY\", \"HYPERTENSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c33cb",
   "metadata": {},
   "source": [
    "Its worthwhile noting that this method returns a Pandas DataFrame, so we can use anything contained in the Pandas library to further filter this dataframe. For instance if we create a list of columns that we're interested in we can use this to only display these columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f450010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_of_interest = [\"USUBJID\", \"SASTDY\", \"SAMODIFY\", \"SAPRESP\", \"SAOCCUR\", 'status']\n",
    "SA.select_variable_from_column(\"SAMODIFY\", \"HYPERTENSION\")[cols_of_interest]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a657d0",
   "metadata": {},
   "source": [
    "When we select only these columns the relationship between SAPRESP, SAOCCUR and status becomes a little more evident too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe9ddf1",
   "metadata": {},
   "source": [
    "We can also print a summary of counts for each column. For example SAMODIFY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.column_summary(\"SAMODIFY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d035d4",
   "metadata": {},
   "source": [
    "We can also use this method to show proportions of each variable as well by adding proportions = True as seen below. Note that that the proportions displayed are the number of rows containing a variable over the total number of rows in SAMODIFY. That is, they are independent of the 'status' variable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.column_summary(\"SAMODIFY\", proportions = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db22883f",
   "metadata": {},
   "source": [
    "However this just gives us the counts / proportions of events that are recorded without any information on the status of the event (e.g Y, N or U). If we set status = True, this will extract this information: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd31adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.column_summary(\"SAMODIFY\", status = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df72a2b",
   "metadata": {},
   "source": [
    "We can also optionally specify some variables if we only want to print some variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e260ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.column_summary(\"SAMODIFY\",  \"ASTHMA\", \"STROKE\", \"TUBERCULOSIS\", status = True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8967ceae",
   "metadata": {},
   "source": [
    "Now we should save our modified DataFrame (with the added status variable) back into a sqlite table: \n",
    "\n",
    "If we want to browse (or access later) we can save this back into a sqlite table. \n",
    "(note this takes some timefor large domains such as SA and IN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fa113",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA.save_to_sqlite(\"SA_tutorial_modified\", DATA_DIRECTORY, DATABASE_FILE )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bf0812",
   "metadata": {},
   "source": [
    "This creates a new table in our existing sqlite database as well as a .pickle file for quicker read and write in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e8be8",
   "metadata": {},
   "source": [
    "## Free Text Variables\n",
    "For most variables in the ISARIC dataset, the xxMODIFY column contains a standardised event name. However for some spontaneously recorded events this might not be the case. In some instances it can be worthwhile checking these entries... \n",
    "\n",
    "In this example we are going to search the SA domain for some terms that might be relevant to Kidney Stones (for which there is no standardised variable in the 'SAMODIFY' column. We use the domain.free_text_search() method. We can enter any terms we wish to search for as strings separated by commas. This method then searches for any of these terms in the relevant column and returns a dataframe with the result. \n",
    "\n",
    "It is worth noting that the Domain.free_text_search() method searches to see if our search terms are substrings of any raw terms. For example searching \"Kidney\" would return rows containing \"Acute Kidney Injury\" as well as \"Kidney Stones\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "stones_frame = SA.free_text_search(\"kidney stones\", \"nephrolithiasis\", \"renal calculi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stones_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb93661",
   "metadata": {},
   "source": [
    "So we found 271 free text entries that are relevant for Kidney stones. . Note that the value of SAPRESP is NaN (missing) as is the value of SAOCCUR. This indicates that the entry was made spontaenously (i.e. not indicated on the CRF) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82044f",
   "metadata": {},
   "source": [
    "# Vaccination Status Example\n",
    "\n",
    "Now we have introduced the basic functionality of our package we are going to give an example of using the package to retrieve the vaccination status of patients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48497899",
   "metadata": {},
   "source": [
    "In this example we need to load the IN domain as this contains information about vaccinations (note we first delete the SA domain from memory to save some space). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f169dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33398df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN = Domain(\"IN\", DATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a4187",
   "metadata": {},
   "source": [
    "We then inspect the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN.columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d016d19",
   "metadata": {},
   "source": [
    "Most of those columns are not relevant to vaccination status so we're going to include only relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6833e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols = ['USUBJID', 'INTRT', 'INMODIFY', 'INPRESP', 'INOCCUR', 'INREFID' ,'INSTDY', 'status']\n",
    "IN.include_columns(relevant_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92bd8ca",
   "metadata": {},
   "source": [
    "While there are derived values for COVID-19 vaccination status in the 'INMODIFY' column, they contain different values depending on the type of vaccination received. Instead we are going to search the 'INTRT' column with a variety of free-text search terms to ensure we get as many COVID-19 vaccination events as possible, including those events that do not contain a value in the standardised column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_vacc = IN.free_text_search(\"COVID-19 Vaccine\", \"ASTRAZENECA\", \"PFIZER\", \"COVISHIELD\",\n",
    "                                 \"SINOVAC\", \"COVID-19 VACCINATION\", \"RECEIVED A COVID-19 VACCIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cfd76",
   "metadata": {},
   "source": [
    "So we found 559,420 rows that are relevant to COVID-19 Vaccination status in the IN domain. Taking a closer look at what the result looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1212a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_vacc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa2335",
   "metadata": {},
   "source": [
    "Lets look at the unique values for each column using some functionality from Pandas. Each column in a pandas DataFrame is stored as a series. We can access the series directly by using 'df.colname' and then using the .unique() method we can find the unique values contained in that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_vacc.INTRT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e9d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_vacc.INMODIFY.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_vacc.INREFID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf6ab6",
   "metadata": {},
   "source": [
    "We can also look at the counts in the 'status' variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_vacc.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459ac32",
   "metadata": {},
   "source": [
    "Great! So now what do we do if we want to save this DataFrame to access it later?\n",
    "\n",
    "We can use the function df_to_sqlite() which saves a DataFrame into the sqlite database created earlier and as a .pickle which we can load quickly into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739011a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_sqlite(covid_vacc, \"vacc_status\", DATA_DIRECTORY, DATABASE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78789349",
   "metadata": {},
   "source": [
    "As you can see the function returns True, meaning the write has been succesful. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}